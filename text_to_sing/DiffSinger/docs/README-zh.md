# DiffSinger: Singing Voice Synthesis via Shallow Diffusion Mechanism
[![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2105.02446)
[![GitHub Stars](https://img.shields.io/github/stars/MoonInTheRiver/DiffSinger?style=social)](https://github.com/MoonInTheRiver/DiffSinger)
[![downloads](https://img.shields.io/github/downloads/MoonInTheRiver/DiffSinger/total.svg)](https://github.com/MoonInTheRiver/DiffSinger/releases)
 | [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-blue)](https://huggingface.co/spaces/NATSpeech/DiffSpeech)
 | [English README](../README.md)

æœ¬ä»“åº“åŒ…å«äº†æˆ‘ä»¬çš„AAAI-2022 [è®ºæ–‡](https://arxiv.org/abs/2105.02446)ä¸­æå‡ºçš„DiffSpeech (ç”¨äºè¯­éŸ³åˆæˆ) ä¸ DiffSinger (ç”¨äºæ­Œå£°åˆæˆ) çš„å®˜æ–¹Pytorchå®ç°ã€‚

<table style="width:100%">
  <tr>
    <th>DiffSinger/DiffSpeechè®­ç»ƒé˜¶æ®µ</th>
    <th>DiffSinger/DiffSpeechæ¨ç†é˜¶æ®µ</th>
  </tr>
  <tr>
    <td><img src="resources/model_a.png" alt="Training" height="300"></td>
    <td><img src="resources/model_b.png" alt="Inference" height="300"></td>
  </tr>
</table>

:tada: :tada: :tada: **ä¸€äº›é‡è¦æ›´æ–°**:
- Mar.2, 2022: [MIDI-æ–°ç‰ˆ](README-SVS-opencpop-e2e.md): é‡å¤§æ›´æ–° :sparkles:
 - Mar.1, 2022: [NeuralSVB](https://github.com/MoonInTheRiver/NeuralSVB), ä¸ºäº†æ­Œå£°ç¾åŒ–ä»»åŠ¡çš„ä»£ç ï¼Œå¼€æºäº† :sparkles:  :sparkles:  :sparkles: .
 - Feb.13, 2022: [NATSpeech](https://github.com/NATSpeech/NATSpeech), ä¸€ä¸ªå‡çº§åçš„ä»£ç æ¡†æ¶, åŒ…å«äº†DiffSpeechå’Œæˆ‘ä»¬NeurIPS-2021çš„å·¥ä½œ[PortaSpeech](https://openreview.net/forum?id=xmJsuh8xlq) å·²ç»å¼€æº! :sparkles: :sparkles: :sparkles:. 
 - Jan.29, 2022: æ”¯æŒäº†[MIDI-æ—§ç‰ˆ](README-SVS-opencpop-cascade.md) ç‰ˆæœ¬çš„æ­Œå£°åˆæˆç³»ç»Ÿ.
 - Jan.13, 2022: æ”¯æŒäº†æ­Œå£°åˆæˆç³»ç»Ÿ, å¼€æºäº†PopCSæ•°æ®é›†.
 - Dec.19, 2021: æ”¯æŒäº†è¯­éŸ³åˆæˆç³»ç»Ÿ. [HuggingFaceğŸ¤— Demo](https://huggingface.co/spaces/NATSpeech/DiffSpeech)
 
:rocket: **æ–°é—»**: 
 - Feb.24, 2022: æˆ‘ä»¬çš„æ–°å·¥ä½œ`NeuralSVB` è¢« ACL-2022 æ¥æ”¶ [![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2202.13277). [éŸ³é¢‘æ¼”ç¤º](https://neuralsvb.github.io).
 - Dec.01, 2021: DiffSingerè¢«AAAI-2022æ¥æ”¶.
 - Sep.29, 2021: æˆ‘ä»¬çš„æ–°å·¥ä½œ`PortaSpeech: Portable and High-Quality Generative Text-to-Speech` è¢«NeurIPS-2021æ¥æ”¶ [![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2109.15166) .
 - May.06, 2021: æˆ‘ä»¬æŠŠè¿™ç¯‡DiffSingeræäº¤åˆ°äº†å…¬å¼€è®ºæ–‡ç½‘ç«™: Arxiv [![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2105.02446).

## å®‰è£…ä¾èµ–
```sh
conda create -n your_env_name python=3.8
source activate your_env_name 
pip install -r requirements_2080.txt   (GPU 2080Ti, CUDA 10.2)
or pip install -r requirements_3090.txt   (GPU 3090, CUDA 11.4)
```

## DiffSpeech (è¯­éŸ³åˆæˆçš„ç‰ˆæœ¬)
### 1. å‡†å¤‡å·¥ä½œ

#### æ•°æ®å‡†å¤‡
a) ä¸‹è½½å¹¶è§£å‹ [LJ Speech dataset](https://keithito.com/LJ-Speech-Dataset/), åˆ›å»ºè½¯é“¾æ¥: `ln -s /xxx/LJSpeech-1.1/ data/raw/`

b) ä¸‹è½½å¹¶è§£å‹ [æˆ‘ä»¬ç”¨MFAé¢„å¤„ç†å¥½çš„å¯¹é½](https://github.com/MoonInTheRiver/DiffSinger/releases/download/pretrain-model/mfa_outputs.tar):  `tar -xvf mfa_outputs.tar; mv mfa_outputs data/processed/ljspeech/`

c) æŒ‰ç…§å¦‚ä¸‹è„šæœ¬ç»™æ•°æ®é›†æ‰“åŒ…ï¼Œæ‰“åŒ…åçš„äºŒè¿›åˆ¶æ–‡ä»¶ç”¨äºåç»­çš„è®­ç»ƒå’Œæ¨ç†.

```sh
export PYTHONPATH=.
CUDA_VISIBLE_DEVICES=0 python data_gen/tts/bin/binarize.py --config configs/tts/lj/fs2.yaml

# `data/binary/ljspeech` will be generated.
```

#### å£°ç å™¨å‡†å¤‡
æˆ‘ä»¬æä¾›äº†[HifiGAN](https://github.com/MoonInTheRiver/DiffSinger/releases/download/pretrain-model/0414_hifi_lj_1.zip)å£°ç å™¨çš„é¢„è®­ç»ƒæ¨¡å‹.
è¯·åœ¨è®­ç»ƒå£°å­¦æ¨¡å‹å‰ï¼Œå…ˆæŠŠå£°ç å™¨æ–‡ä»¶è§£å‹åˆ°`checkpoints`é‡Œã€‚

### 2. è®­ç»ƒæ ·ä¾‹

é¦–å…ˆä½ éœ€è¦ä¸€ä¸ªé¢„è®­ç»ƒå¥½çš„FastSpeech2å­˜æ¡£ç‚¹. ä½ å¯ä»¥ç”¨[æˆ‘ä»¬é¢„è®­ç»ƒå¥½çš„æ¨¡å‹](https://github.com/MoonInTheRiver/DiffSinger/releases/download/pretrain-model/fs2_lj_1.zip), æˆ–è€…è·‘ä¸‹é¢è¿™ä¸ªæŒ‡ä»¤ä»é›¶å¼€å§‹è®­ç»ƒFastSpeech2:
```sh
CUDA_VISIBLE_DEVICES=0 python tasks/run.py --config configs/tts/lj/fs2.yaml --exp_name fs2_lj_1 --reset
```
ç„¶åä¸ºäº†è®­ç»ƒDiffSpeech, è¿è¡Œ:
```sh
CUDA_VISIBLE_DEVICES=0 python tasks/run.py --config usr/configs/lj_ds_beta6.yaml --exp_name lj_ds_beta6_1213 --reset
```

è®°å¾—é’ˆå¯¹ä½ çš„è·¯å¾„ä¿®æ”¹`usr/configs/lj_ds_beta6.yaml`é‡Œ"fs2_ckpt"è¿™ä¸ªå‚æ•°.

### 3. æ¨ç†æ ·ä¾‹

```sh
CUDA_VISIBLE_DEVICES=0 python tasks/run.py --config usr/configs/lj_ds_beta6.yaml --exp_name lj_ds_beta6_1213 --reset --infer
```

æˆ‘ä»¬ä¹Ÿæä¾›äº†:
 - [DiffSpeech](https://github.com/MoonInTheRiver/DiffSinger/releases/download/pretrain-model/lj_ds_beta6_1213.zip)çš„é¢„è®­ç»ƒæ¨¡å‹;
 - [FastSpeech 2](https://github.com/MoonInTheRiver/DiffSinger/releases/download/pretrain-model/fs2_lj_1.zip)çš„é¢„è®­ç»ƒæ¨¡å‹, è¿™æ˜¯ä¸ºäº†DiffSpeeché‡Œçš„æµ…æ‰©æ•£æœºåˆ¶;
 
è®°å¾—æŠŠé¢„è®­ç»ƒæ¨¡å‹æ”¾åœ¨ `checkpoints` ç›®å½•.

## DiffSinger (æ­Œå£°åˆæˆçš„ç‰ˆæœ¬)

### 0. æ•°æ®è·å–
- è§ [ç”³è¯·è¡¨](https://github.com/MoonInTheRiver/DiffSinger/blob/master/resources/apply_form.md).
- æ•°æ®é›† [é¢„è§ˆ](https://github.com/MoonInTheRiver/DiffSinger/releases/download/pretrain-model/popcs_preview.zip).

### 1. Preparation
#### æ•°æ®å‡†å¤‡
a) ä¸‹è½½å¹¶è§£å‹PopCS, åˆ›å»ºè½¯é“¾æ¥: `ln -s /xxx/popcs/ data/processed/popcs`

b) æŒ‰ç…§å¦‚ä¸‹è„šæœ¬ç»™æ•°æ®é›†æ‰“åŒ…ï¼Œæ‰“åŒ…åçš„äºŒè¿›åˆ¶æ–‡ä»¶ç”¨äºåç»­çš„è®­ç»ƒå’Œæ¨ç†.
```sh
export PYTHONPATH=.
CUDA_VISIBLE_DEVICES=0 python data_gen/tts/bin/binarize.py --config usr/configs/popcs_ds_beta6.yaml
# `data/binary/popcs-pmf0` ä¼šç”Ÿæˆå‡ºæ¥.
```

#### å£°ç å™¨å‡†å¤‡
æˆ‘ä»¬æä¾›äº†[HifiGAN-Singing](https://github.com/MoonInTheRiver/DiffSinger/releases/download/pretrain-model/0109_hifigan_bigpopcs_hop128.zip)çš„é¢„è®­ç»ƒæ¨¡å‹, å®ƒä¸“é—¨ä¸ºäº†æ­Œå£°åˆæˆç³»ç»Ÿè®¾è®¡, é‡‡ç”¨äº†NSFçš„æŠ€æœ¯ã€‚
è¯·åœ¨è®­ç»ƒå£°å­¦æ¨¡å‹å‰ï¼Œå…ˆæŠŠå£°ç å™¨æ–‡ä»¶è§£å‹åˆ°`checkpoints`é‡Œã€‚

(æ›´æ–°: ä½ ä¹Ÿå¯ä»¥å°†æˆ‘ä»¬æä¾›çš„[è®­ç»ƒæ›´å¤šæ­¥æ•°çš„å­˜æ¡£ç‚¹](https://github.com/MoonInTheRiver/DiffSinger/releases/download/pretrain-model/model_ckpt_steps_1512000.ckpt)æ”¾åˆ°å£°ç å™¨çš„æ–‡ä»¶å¤¹é‡Œ)

è¿™ä¸ªå£°ç å™¨æ˜¯åœ¨å¤§çº¦70å°æ—¶çš„è¾ƒå¤§æ•°æ®é›†ä¸Šè®­ç»ƒçš„, å¯ä»¥è¢«è®¤ä¸ºæ˜¯ä¸€ä¸ªé€šç”¨å£°ç å™¨ã€‚

### 2. è®­ç»ƒæ ·ä¾‹
é¦–å…ˆä½ éœ€è¦ä¸€ä¸ªé¢„è®­ç»ƒå¥½çš„FFT-Singer. ä½ å¯ä»¥ç”¨[æˆ‘ä»¬é¢„è®­ç»ƒå¥½çš„æ¨¡å‹](https://github.com/MoonInTheRiver/DiffSinger/releases/download/pretrain-model/popcs_fs2_pmf0_1230.zip), æˆ–è€…ç”¨å¦‚ä¸‹è„šæœ¬ä»é›¶è®­ç»ƒFFT-Singer:

```sh
# First, train fft-singer;
CUDA_VISIBLE_DEVICES=0 python tasks/run.py --config usr/configs/popcs_fs2.yaml --exp_name popcs_fs2_pmf0_1230 --reset
# Then, infer fft-singer;
CUDA_VISIBLE_DEVICES=0 python tasks/run.py --config usr/configs/popcs_fs2.yaml --exp_name popcs_fs2_pmf0_1230 --reset --infer 
```

ç„¶å, ä¸ºäº†è®­ç»ƒDiffSinger, è¿è¡Œ:
```sh
CUDA_VISIBLE_DEVICES=0 python tasks/run.py --config usr/configs/popcs_ds_beta6_offline.yaml --exp_name popcs_ds_beta6_offline_pmf0_1230 --reset
```

è®°å¾—é’ˆå¯¹ä½ çš„è·¯å¾„ä¿®æ”¹`usr/configs/popcs_ds_beta6_offline.yaml`é‡Œ"fs2_ckpt"è¿™ä¸ªå‚æ•°.

### 3. æ¨ç†æ ·ä¾‹
```sh
CUDA_VISIBLE_DEVICES=0 python tasks/run.py --config usr/configs/popcs_ds_beta6_offline.yaml --exp_name popcs_ds_beta6_offline_pmf0_1230 --reset --infer
```

æˆ‘ä»¬ä¹Ÿæä¾›äº†:
 - [DiffSinger](https://github.com/MoonInTheRiver/DiffSinger/releases/download/pretrain-model/popcs_ds_beta6_offline_pmf0_1230.zip)çš„é¢„è®­ç»ƒæ¨¡å‹;
 - [FFT-Singer](https://github.com/MoonInTheRiver/DiffSinger/releases/download/pretrain-model/popcs_fs2_pmf0_1230.zip)çš„é¢„è®­ç»ƒæ¨¡å‹, è¿™æ˜¯ä¸ºäº†DiffSingeré‡Œçš„æµ…æ‰©æ•£æœºåˆ¶;

è®°å¾—æŠŠé¢„è®­ç»ƒæ¨¡å‹æ”¾åœ¨ `checkpoints` ç›®å½•.

*è¯·æ³¨æ„ï¼š*

-*æˆ‘ä»¬åŸå§‹è®ºæ–‡ä¸­çš„PWGç‰ˆæœ¬å£°ç å™¨å·²æŠ•å…¥å•†ä¸šä½¿ç”¨ï¼Œå› æ­¤æˆ‘ä»¬æä¾›æ­¤HifiGANç‰ˆæœ¬å£°ç å™¨ä½œä¸ºæ›¿ä»£å“ã€‚*

-*æˆ‘ä»¬è¿™ç¯‡è®ºæ–‡å‡è®¾æä¾›çœŸå®çš„F0æ¥è¿›è¡Œå®éªŒï¼Œå¦‚[1][2][3]ç­‰å‰ä½œæ‰€åšçš„é‚£æ ·ï¼Œé‡ç‚¹åœ¨é¢‘è°±å»ºæ¨¡ä¸Šï¼Œè€ŒéF0æ›²çº¿çš„é¢„æµ‹ã€‚å¦‚æœä½ æƒ³å¯¹MIDIæ•°æ®è¿›è¡Œå®éªŒï¼Œä»MIDIå’Œæ­Œè¯é¢„æµ‹F0æ›²çº¿ï¼ˆæ˜¾å¼æˆ–éšå¼ï¼‰ï¼Œè¯·æŸ¥çœ‹æ–‡æ¡£[MIDI-old-version](README-SVS-opencpop-cascade.md) æˆ– [MIDI-new-version](README-SVS-opencpop-e2e.md)ã€‚ç›®å‰å·²ç»æ”¯æŒçš„MIDIæ•°æ®é›†æœ‰: Opencpop*

[1] Adversarially trained multi-singer sequence-to-sequence singing synthesizer. Interspeech 2020.

[2] SEQUENCE-TO-SEQUENCE SINGING SYNTHESIS USING THE FEED-FORWARD TRANSFORMER. ICASSP 2020.

[3] DeepSinger : Singing Voice Synthesis with Data Mined From the Web. KDD 2020.

## Tensorboard
```sh
tensorboard --logdir_spec exp_name
```
<table style="width:100%">
  <tr>
    <td><img src="resources/tfb.png" alt="Tensorboard" height="250"></td>
  </tr>
</table>

## Mel å¯è§†åŒ–
æ²¿ç€çºµè½´, DiffSpeech: [0-80]; FastSpeech2: [80-160].

<table style="width:100%">
  <tr>
    <th>DiffSpeech vs. FastSpeech 2</th>
  </tr>
  <tr>
    <td><img src="resources/diffspeech-fs2.png" alt="DiffSpeech-vs-FastSpeech2" height="250"></td>
  </tr>
  <tr>
    <td><img src="resources/diffspeech-fs2-1.png" alt="DiffSpeech-vs-FastSpeech2" height="250"></td>
  </tr>
  <tr>
    <td><img src="resources/diffspeech-fs2-2.png" alt="DiffSpeech-vs-FastSpeech2" height="250"></td>
  </tr>
</table>

## Audio Demos
éŸ³é¢‘æ ·æœ¬å¯ä»¥çœ‹æˆ‘ä»¬çš„[æ ·ä¾‹é¡µ](https://diffsinger.github.io/).

æˆ‘ä»¬ä¹Ÿæ”¾äº†éƒ¨åˆ†ç”±DiffSpeech+HifiGAN (æ ‡è®°ä¸º[P]) å’Œ GTmel+HifiGAN (æ ‡è®°ä¸º[G]) ç”Ÿæˆçš„æµ‹è¯•é›†éŸ³é¢‘æ ·ä¾‹åœ¨ï¼š[resources/demos_1213](../resources/demos_1213). 

(å¯¹åº”è¿™ä¸ªé¢„è®­ç»ƒå‚æ•°ï¼š[DiffSpeech](https://github.com/MoonInTheRiver/DiffSinger/releases/download/pretrain-model/lj_ds_beta6_1213.zip))

---
:rocket: :rocket: :rocket: **æ›´æ–°:**

æ–°ç”Ÿæˆçš„æ­Œå£°æ ·ä¾‹åœ¨ï¼š[resources/demos_0112](../resources/demos_0112).

## Citation
å¦‚æœæœ¬ä»“åº“å¯¹ä½ çš„ç ”ç©¶å’Œå·¥ä½œæœ‰ç”¨ï¼Œè¯·å¼•ç”¨ä»¥ä¸‹è®ºæ–‡ï¼š

    @article{liu2021diffsinger,
      title={Diffsinger: Singing voice synthesis via shallow diffusion mechanism},
      author={Liu, Jinglin and Li, Chengxi and Ren, Yi and Chen, Feiyang and Liu, Peng and Zhao, Zhou},
      journal={arXiv preprint arXiv:2105.02446},
      volume={2},
      year={2021}}


## é¸£è°¢
æˆ‘ä»¬çš„ä»£ç åŸºäºå¦‚ä¸‹ä»“åº“:
* [denoising-diffusion-pytorch](https://github.com/lucidrains/denoising-diffusion-pytorch)
* [PyTorch Lightning](https://github.com/PyTorchLightning/pytorch-lightning)
* [ParallelWaveGAN](https://github.com/kan-bayashi/ParallelWaveGAN)
* [HifiGAN](https://github.com/jik876/hifi-gan)
* [espnet](https://github.com/espnet/espnet)
* [DiffWave](https://github.com/lmnt-com/diffwave)